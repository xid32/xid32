### Hi there üëã

I'm **[Xingjian Diao](https://xid32.github.io/)**, a Ph.D. student in Computer Science at Dartmouth College üå≤, co-advised by [Prof. Soroush Vosoughi](https://www.cs.dartmouth.edu/~soroush/) and [Prof. Jiang Gui](https://scholar.google.com/citations?user=Yd2HEqsAAAAJ&hl=en).

Previously, I completed my M.S. in Computer Science at Northwestern University üíú, advised by [Prof. Nabil Alshurafa](https://www.thehabitslab.com/). I received my B.S. in Computer Science from the University of Pittsburgh üíô, graduating with Cum Laude honors.

---

### üîç Research

My research focuses on **multimodal learning** for video, audio, and language understanding. I have developed methods for multimodal reasoning, efficient multimodal learning, and generative multimodal modeling, aiming to build scalable and generalizable multimodal models that advance multimodal question answering, video understanding, and audio‚Äìvisual reasoning across complex real-world scenarios and dynamic environments. Highlights of my work include:

- **[SoundMind: RL-Incentivized Logic Reasoning for Audio-Language Models](https://aclanthology.org/2025.emnlp-main.27.pdf)**  
  *EMNLP 2025 ‚Äî (Oral Presentation, top 4.35%)*  
  **Xingjian Diao**, Chunhui Zhang, Keyi Kong, Weiyi Wu, Chiyu Ma, Zhongyu Ouyang, Peijun Qing, Soroush Vosoughi, Jiang Gui  

- **[ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering](https://aclanthology.org/2025.emnlp-main.54.pdf)**  
  *EMNLP 2025 ‚Äî (Oral Presentation, top 4.35%)*  
  **Xingjian Diao**, Weiyi Wu, Keyi Kong, Peijun Qing, Xinwen Xu, Ming Cheng, Soroush Vosoughi, Jiang Gui  

- **[Temporal Working Memory: Query-Guided Temporal Segment Refinement for Enhanced Multimodal Understanding](https://aclanthology.org/2025.findings-naacl.189.pdf)**  
  *Findings of NAACL 2025 ‚Äî Guarini Graduate Student Travel Award (Dartmouth College)*  
  **Xingjian Diao**, Chunhui Zhang, Weiyi Wu, Zhongyu Ouyang, Peijun Qing, Ming Cheng, Soroush Vosoughi, Jiang Gui  

- **[Learning Musical Representations for Music Performance Question Answering](https://aclanthology.org/2024.findings-emnlp.159.pdf)**  
  *Findings of EMNLP 2024 ‚Äî BMDS Travel Award (Dartmouth College)*  
  **Xingjian Diao**, Chunhui Zhang, Tingxuan Wu, Ming Cheng, Zhongyu Ouyang, Weiyi Wu, Jiang Gui
  
- **[FT2TF: First-Person Statement Text-To-Talking Face Generation](https://openaccess.thecvf.com/content/WACV2025/papers/Diao_FT2TF_First-Person_Statement_Text-To-Talking_Face_Generation_WACV_2025_paper.pdf)**  
  *WACV 2025*  
  **Xingjian Diao**, Ming Cheng, Wayner Barrios, SouYoung Jin  

- **[Learning Sparsity for Effective and Efficient Music Performance Question Answering](https://aclanthology.org/2025.acl-short.12.pdf)**  
  *ACL 2025*  
  **Xingjian Diao**, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui  

---

### üßë‚Äçüíª Internship Experience

* **Amazon Science (Jun 2025 ‚Äì Sept 2025)**\
  *Applied Scientist Intern, Santa Cruz, CA*\
  Research on **multimodal learning**.

---
